{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "sys.path.append(nb_dir)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from GELMMnet import GELMMnet, kinship\n",
    "print(nb_dir)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Dim: (1000, 1000)\n",
      "X Dim (176, 1000)\n",
      "W 0.611532483529\n",
      "MSR: 0.711151836402\n"
     ]
    }
   ],
   "source": [
    "from GELMMnet import kinship, GELMMnet, normalized_laplacian, transform_kernel_to_distance\n",
    "import scipy as SP\n",
    "\n",
    "geno_filename = os.path.join(nb_dir,'./test/genotypes.csv')\n",
    "X = SP.genfromtxt(geno_filename)\n",
    "y = SP.genfromtxt(os.path.join(nb_dir,\"test/phenotypes.csv\"))\n",
    "K = kinship(X)\n",
    "P = np.identity(X.shape[1])\n",
    "n_s,n_v = X.shape\n",
    "n_train = 150\n",
    "n_test = n_s - n_train\n",
    "\n",
    "\n",
    "# split into training and testing\n",
    "train_idx = SP.random.permutation(SP.arange(n_s))\n",
    "test_idx = train_idx[n_train:]\n",
    "train_idx = train_idx[:n_train]\n",
    "\n",
    "# X[train_idx],K[train_idx][:,train_idx],y[train_idx]\n",
    "\n",
    "print(\"P Dim:\",P.shape)\n",
    "print(\"X Dim\", X.shape)\n",
    "glm = GELMMnet(y[train_idx], X[train_idx], K[train_idx][:,train_idx])\n",
    "glm.train(P, l1=1, l2=0.5, max_iter=1000, eps=1.0e-5)\n",
    "\n",
    "y_pred = glm.predict(X[test_idx])\n",
    "msr_regreg = mean_squared_error(y[test_idx],y_pred)\n",
    "w_regreg = glm.w\n",
    "print(\"W\",w_regreg.sum())\n",
    "print(\"MSR:\",msr_regreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " [1]  2.90117931  2.09140871  0.10536154  0.07723765 -0.17150755 -0.13135784\n",
       " [7]  0.13166391  0.02265503 -0.09731043  0.00000000\n",
       "\n",
       "Call:\n",
       "fixedLassoInf(x = x, y = y, beta = beta, lambda = lambda, sigma = sigma)\n",
       "\n",
       "Standard deviation of noise (specified or estimated) sigma = 1.000\n",
       "\n",
       "Testing results at lambda = 0.800, with alpha = 0.100\n",
       "\n",
       " Var   Coef Z-score P-value LowConfPt UpConfPt LowTailArea UpTailArea\n",
       "   1  2.912  18.897   0.000     2.655    3.196       0.048      0.049\n",
       "   2  2.123  13.803   0.000     1.856    2.377       0.049      0.049\n",
       "   3  0.141   0.817   0.495    -0.728    0.404       0.049      0.049\n",
       "   4  0.109   0.699   0.578    -0.854    0.337       0.050      0.049\n",
       "   5 -0.206  -1.240   0.257    -0.486    0.310       0.048      0.049\n",
       "   6 -0.145  -0.968   0.358    -0.395    0.392       0.048      0.049\n",
       "   7  0.141   0.909   0.374    -0.432    0.477       0.050      0.049\n",
       "   8  0.045   0.304   0.865    -2.872    0.165       0.050      0.050\n",
       "   9 -0.113  -0.722   0.510    -0.355    0.658       0.050      0.049\n",
       "\n",
       "Note: coefficients shown are partial regression coefficients\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -o x,y,out\n",
    "library(glmnet)\n",
    "library(selectiveInference)\n",
    "set.seed(43)\n",
    "n = 50\n",
    "p = 10\n",
    "sigma = 1\n",
    "x = matrix(rnorm(n*p),n,p)\n",
    "x=scale(x,TRUE,TRUE)\n",
    "beta = c(3,2,rep(0,p-2))\n",
    "y = x%*%beta + sigma*rnorm(n)\n",
    "# first run glmnet\n",
    "gfit = glmnet(x,y,standardize=FALSE)\n",
    "# extract coef for a given lambda; note the 1/n factor!\n",
    "# (and we don't save the intercept term) fixedLassoInf 7 \n",
    "lambda = .8\n",
    "beta = coef(gfit, s=lambda/n, exact=TRUE)[-1]\n",
    "print(beta)\n",
    "# compute fixed lambda p-values and selection intervals\n",
    "out = fixedLassoInf(x,y,beta,lambda,sigma=sigma)\n",
    "out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1\n",
       "[1] 7.364081e-16\n",
       "  [1] 5.932295e-137 1.663816e-134 4.666386e-132 1.308724e-129 3.670350e-127\n",
       "  [6] 1.029338e-124 2.886686e-122 8.095269e-120 2.270140e-117 6.365943e-115\n",
       " [11] 1.785095e-112 5.005495e-110 1.403523e-107 3.935297e-105 1.103367e-102\n",
       " [16] 3.093472e-100  8.672703e-98  2.431328e-95  6.815722e-93  1.910547e-90\n",
       " [21]  5.355247e-88  1.500979e-85  4.206697e-83  1.178898e-80  3.303521e-78\n",
       " [26]  9.256357e-76  2.593353e-73  7.265027e-71  2.034989e-68  5.699414e-66\n",
       " [31]  1.596009e-63  4.468579e-61  1.250903e-58  3.500964e-56  9.795997e-54\n",
       " [36]  2.740260e-51  7.663006e-49  2.142145e-46  5.985691e-44  1.671715e-41\n",
       " [41]  4.666066e-39  1.301450e-36  3.626802e-34  1.009601e-31  2.806628e-29\n",
       " [46]  7.788677e-27  2.156516e-24  5.952676e-22  1.636168e-19  4.469754e-17\n",
       " [51]  1.209780e-14  0.000000e+00  0.000000e+00  2.065933e-07  4.486003e-05\n",
       " [56]  6.585602e-03  2.551857e-01  9.112382e-01  9.996221e-01  1.000000e+00\n",
       " [61]  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       " [66]  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       " [71]  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       " [76]  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       " [81]  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00           NaN\n",
       " [86]           NaN           NaN           NaN           NaN           NaN\n",
       " [91]           NaN           NaN           NaN           NaN           NaN\n",
       " [96]           NaN           NaN           NaN           NaN           NaN\n",
       "[1] \"i2  58 0.975\"\n",
       "[1] \"left  11.1111111111111  right  13.1313131313131  val  0.025\"\n",
       "[1] \"TRUE  ii \"\n",
       " [1]  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
       "[20]  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
       "[39]  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
       "[58]  89  90  91  92  93  94  95  96  97  98  99 100\n",
       "[1] \"left  15.1515151515152  right  17.1717171717172  val  0.975\"\n",
       "[1] \"FALSE  ii \"\n",
       " [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
       "[26] 26 27 28 29 30\n",
       "[1] \"Ci  1.80277038518188  mj  0.153776784553243  sd  0.153776784553243\"\n",
       "[2] \"Ci  2.42409072681115  mj  0.153776784553243  sd  0.153776784553243\"\n",
       "[1] 1.803 2.424\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(glmnet)\n",
    "library(selectiveInference)\n",
    "\n",
    "# Returns Prob(Z>z | Z in [a,b]), where mean can be a vector\n",
    "\n",
    "tnorm.surv <- function(z, mean, sd, a, b, bits=NULL) {\n",
    "  z = max(min(z,b),a)\n",
    "  \n",
    "  # Check silly boundary cases\n",
    "  p = numeric(length(mean))\n",
    "  p[mean==-Inf] = 0\n",
    "  p[mean==Inf] = 1\n",
    "  \n",
    "  # Try the multi precision floating point calculation first\n",
    "  o = is.finite(mean)\n",
    "  mm = mean[o]\n",
    "  pp = mpfr.tnorm.surv(z,mm,sd,a,b,bits)\n",
    "  # If there are any NAs, then settle for an approximation\n",
    "  oo = is.na(pp)\n",
    "  if (any(oo)) pp[oo] = bryc.tnorm.surv(z,mm[oo],sd,a,b)\n",
    "    \n",
    "  p[o] = pp\n",
    "  #print(paste(\"z\",z,\"mean\",mean,\"sd\",sd,\"a\",a,\"b\",b,\"pval\",p))\n",
    "  return(p)\n",
    "}\n",
    "\n",
    "# Returns Prob(Z>z | Z in [a,b]), where mean cane be a vector, using\n",
    "# multi precision floating point calculations thanks to the Rmpfr package\n",
    "\n",
    "mpfr.tnorm.surv <- function(z, mean=0, sd=1, a, b, bits=NULL) {\n",
    "  # If bits is not NULL, then we are supposed to be using Rmpf\n",
    "  # (note that this was fail if Rmpfr is not installed; but\n",
    "  # by the time this function is being executed, this should\n",
    "  # have been properly checked at a higher level; and if Rmpfr\n",
    "  # is not installed, bits would have been previously set to NULL)\n",
    "  #if (!is.null(bits)) {\n",
    "  #  z = Rmpfr::mpfr((z-mean)/sd, precBits=bits)\n",
    "  #  a = Rmpfr::mpfr((a-mean)/sd, precBits=bits)\n",
    "  #  b = Rmpfr::mpfr((b-mean)/sd, precBits=bits)\n",
    "  #  return(as.numeric((Rmpfr::pnorm(b)-Rmpfr::pnorm(z))/\n",
    "  #                    (Rmpfr::pnorm(b)-Rmpfr::pnorm(a))))\n",
    "  #}\n",
    "  \n",
    "  # Else, just use standard floating point calculations\n",
    "  z = (z-mean)/sd\n",
    "  a = (a-mean)/sd\n",
    "  b = (b-mean)/sd\n",
    "  return((pnorm(b)-pnorm(z))/(pnorm(b)-pnorm(a)))\n",
    "}\n",
    "\n",
    "# Returns Prob(Z>z | Z in [a,b]), where mean can be a vector, based on\n",
    "# A UNIFORM APPROXIMATION TO THE RIGHT NORMAL TAIL INTEGRAL, W Bryc\n",
    "# Applied Mathematics and Computation\n",
    "# Volume 127, Issues 23, 15 April 2002, Pages 365--374\n",
    "# https://math.uc.edu/~brycw/preprint/z-tail/z-tail.pdf\n",
    "\n",
    "bryc.tnorm.surv <- function(z, mean=0, sd=1, a, b) {\n",
    "  z = (z-mean)/sd\n",
    "  a = (a-mean)/sd\n",
    "  b = (b-mean)/sd\n",
    "  n = length(mean)\n",
    "\n",
    "  term1 = exp(z*z)\n",
    "  o = a > -Inf\n",
    "  term1[o] = ff(a[o])*exp(-(a[o]^2-z[o]^2)/2)\n",
    "  term2 = rep(0,n)\n",
    "  oo = b < Inf\n",
    "  term2[oo] = ff(b[oo])*exp(-(b[oo]^2-z[oo]^2)/2)\n",
    "  p = (ff(z)-term2)/(term1-term2)\n",
    "\n",
    "  # Sometimes the approximation can give wacky p-values,\n",
    "  # outside of [0,1] ..\n",
    "  #p[p<0 | p>1] = NA\n",
    "  old = p\n",
    "  p = pmin(1,pmax(0,p))\n",
    "\n",
    "  return(p)\n",
    "}\n",
    "\n",
    "ff <- function(z) {\n",
    "  return((z^2+5.575192695*z+12.7743632)/\n",
    "         (z^3*sqrt(2*pi)+14.38718147*z*z+31.53531977*z+2*12.77436324))\n",
    "}\n",
    "\n",
    "# Return Prob(Z>z | Z in [a,b]), where mean can be a vector, based on\n",
    "# Riemann approximation tricks, by Max G'Sell\n",
    "\n",
    "gsell.tnorm.surv <- function(z, mean=0, sd=1, a, b) {\n",
    "  return(max.approx.frac(a/sd,b/sd,z/sd,mean/sd))\n",
    "}\n",
    "\n",
    "    \n",
    "pinv <- function(A, tol=.Machine$double.eps) {\n",
    "  e = eigen(A)\n",
    "  v = Re(e$vec)\n",
    "  d = Re(e$val)\n",
    "  d[d > tol] = 1/d[d > tol]\n",
    "  d[d < tol] = 0\n",
    "  if (length(d)==1) return(v*d*v)\n",
    "  else return(v %*% diag(d) %*% t(v))\n",
    "}\n",
    "\n",
    "      \n",
    "poly.pval <- function(y, G, u, v, sigma, bits=NULL) {\n",
    "  z = sum(v*y)\n",
    "  vv = sum(v^2)\n",
    "  sd = sigma*sqrt(vv)\n",
    "  \n",
    "  rho = G %*% v / vv\n",
    " \n",
    "  vec = (u - G %*% y + rho*z) / rho\n",
    "  \n",
    "  vlo = suppressWarnings(max(vec[rho>0]))\n",
    "  vup = suppressWarnings(min(vec[rho<0]))\n",
    "\n",
    "  pv = tnorm.surv(z,0,sd,vlo,vup,bits)\n",
    "  print(pv)\n",
    "  return(list(pv=pv,vlo=vlo,vup=vup))\n",
    "}\n",
    "      \n",
    "      \n",
    "poly.int <- function(y, G, u, v, sigma, alpha, gridrange=c(-100,100),\n",
    "                     gridpts=100, griddepth=2, flip=FALSE, bits=NULL) {\n",
    "  \n",
    "  z = sum(v*y)\n",
    "  vv = sum(v^2)\n",
    "  sd = sigma*sqrt(vv)\n",
    "  \n",
    "  rho = G %*% v / vv\n",
    "  vec = (u - G %*% y + rho*z) / rho\n",
    "  vlo = suppressWarnings(max(vec[rho>0]))\n",
    "  vup = suppressWarnings(min(vec[rho<0]))\n",
    "  \n",
    "  xg = seq(gridrange[1]*sd,gridrange[2]*sd,length=gridpts) \n",
    "  \n",
    "  fun = function(x) { tnorm.surv(z,x,sd,vlo,vup,bits) }\n",
    "\n",
    "  int = grid.search(xg,fun,alpha/2,1-alpha/2,gridpts,griddepth)\n",
    " \n",
    "  tailarea = c(fun(int[1]),1-fun(int[2]))\n",
    "\n",
    "  if (flip) {\n",
    "    int = -int[2:1]\n",
    "    tailarea = tailarea[2:1]\n",
    "  }\n",
    "  \n",
    "  return(list(int=int,tailarea=tailarea))\n",
    "}\n",
    "\n",
    "##############################\n",
    "\n",
    "# Assuming that grid is in sorted order from smallest to largest,\n",
    "# and vals are monotonically increasing function values over the\n",
    "# grid, returns the grid end points such that the corresponding\n",
    "# vals are approximately equal to {val1, val2}\n",
    "\n",
    "grid.search <- function(grid, fun, val1, val2, gridpts=100, griddepth=2) {\n",
    "  n = length(grid)\n",
    "  vals = fun(grid)\n",
    "  \n",
    "  print(vals)\n",
    "    \n",
    "  ii = which(vals >= val1)\n",
    "  jj = which(vals <= val2)\n",
    "  if (length(ii)==0) return(c(grid[n],Inf))   # All vals < val1\n",
    "  if (length(jj)==0) return(c(-Inf,grid[1]))  # All vals > val2\n",
    "  # RJT: the above logic is correct ... but for simplicity, instead,\n",
    "  # we could just return c(-Inf,Inf) \n",
    " \n",
    "  i1 = min(ii); i2 = max(jj)\n",
    "  print(paste(\"i2 \", i2, val2))\n",
    "  if (i1==1) lo = -Inf\n",
    "  else lo = grid.bsearch(grid[i1-1],grid[i1],fun,val1,gridpts,\n",
    "         griddepth-1,below=TRUE)\n",
    "  if (i2==n) hi = Inf\n",
    "  else hi = grid.bsearch(grid[i2],grid[i2+1],fun,val2,gridpts,\n",
    "         griddepth-1,below=FALSE)\n",
    " \n",
    "  return(c(lo,hi))\n",
    "}\n",
    "\n",
    "# Repeated bin search to find the point x in the interval [left, right]\n",
    "# that satisfies f(x) approx equal to val. If below=TRUE, then we seek\n",
    "# x such that the above holds and f(x) <= val; else we seek f(x) >= val.\n",
    "\n",
    "grid.bsearch <- function(left, right, fun, val, gridpts=100, griddepth=1, below=TRUE) {\n",
    "  n = gridpts\n",
    "  depth = 1\n",
    "  print(paste(\"left \",left, \" right \",right, \" val \", val))\n",
    "\n",
    "  while (depth <= griddepth) {\n",
    "    grid = seq(left,right,length=n)\n",
    "    vals = fun(grid)\n",
    "    \n",
    "    if (below) {\n",
    "      ii = which(vals >= val)\n",
    "      print(paste(below,\" ii \"))\n",
    "      print(ii)\n",
    "      if (length(ii)==0){\n",
    "          #print(paste(below,\" ii empty \", grid[n]))\n",
    "          return(grid[n])\n",
    "      }    # All vals < val (shouldn't happen)\n",
    "      if ((i0=min(ii))==1){\n",
    "          #print(paste(below,\" i0==1 \", grid[1]))\n",
    "          return(grid[1])\n",
    "      }  # All vals > val (shouldn't happen)\n",
    "      left = grid[i0-1]\n",
    "      right = grid[i0]\n",
    "    }\n",
    "    \n",
    "    else {\n",
    "      ii = which(vals <= val)\n",
    "      print(paste(below,\" ii \"))\n",
    "      print(ii)\n",
    "      if (length(ii)==0) {\n",
    "          #print(paste(below,\" ii empty \", grid[1]))\n",
    "          return(grid[1])   # All vals > val (shouldn't happen)\n",
    "        }\n",
    "      if ((i0=max(ii))==n){ \n",
    "          #print(paste(below,\" i0==n \", grid[n]))\n",
    "          return(grid[n]) # All vals < val (shouldn't happen)\n",
    "        }\n",
    "      left = grid[i0]\n",
    "      right = grid[i0+1]\n",
    "    }\n",
    "\n",
    "    depth = depth+1\n",
    "  }\n",
    "  #print(paste(below, \" bound \", ifelse(below, left, right)))\n",
    "  return(ifelse(below, left, right))\n",
    "}\n",
    "      \n",
    "set.seed(43)\n",
    "n = 50\n",
    "p = 10\n",
    "sigma = 1\n",
    "x = matrix(rnorm(n*p),n,p)\n",
    "x=scale(x,TRUE,TRUE)\n",
    "beta = c(3,2,rep(0,p-2))\n",
    "y = x%*%beta + sigma*rnorm(n)\n",
    "gfit = glmnet(x,y,standardize=FALSE)\n",
    "# extract coef for a given lambda; note the 1/n factor!\n",
    "# (and we don't save the intercept term) fixedLassoInf 7 \n",
    "lambda = .8\n",
    "beta = coef(gfit, s=lambda/n, exact=TRUE)[-1]\n",
    "      \n",
    "w = beta\n",
    "a = w != 0\n",
    "\n",
    "\n",
    "xa = x[,a,drop=F]\n",
    "xac = x[,!a,drop=F]\n",
    "xai = pinv(crossprod(xa))\n",
    "xap = xai %*% t(xa)\n",
    "za = sign(beta[a])\n",
    "dz = diag(za)\n",
    "\n",
    "G = -rbind(\n",
    "   #   1/lambda * t(xac) %*% P,\n",
    "   # -1/lambda * t(xac) %*% P,\n",
    "    -dz %*% xap\n",
    "      )\n",
    "u = -c(\n",
    "   #   1 - t(xac) %*% t(xap) %*% za,\n",
    "   #   1 + t(xac) %*% t(xap) %*% za,\n",
    "    -lambda * dz %*% xai %*% za)\n",
    "\n",
    " \n",
    "M = xap\n",
    "j = 2      \n",
    "vj = M[j,]\n",
    "mj = sqrt(sum(vj^2))\n",
    "vj = vj / mj        # Standardize (divide by norm of vj)\n",
    "sign_j = sign(sum(vj*y))\n",
    "print(sign_j)\n",
    "vj = sign_j * vj\n",
    "vj\n",
    "r = poly.pval(y,G,u,vj,1.)\n",
    "vmat = vj * mj * sign_j\n",
    "gridrange=c(-100,100)\n",
    "alpha=0.05\n",
    "          \n",
    "a = poly.int(y,G,u,vj,sigma,alpha,gridrange=gridrange,\n",
    "      flip=(sign_j==-1),bits=NULL)\n",
    "ci = a$int * mj # Unstandardize (mult by norm of vj)\n",
    "tailarea = a$tailarea\n",
    "sd = sigma*sqrt(sum(vmat^2))\n",
    "print(paste(\"Ci \",ci,\" mj \", mj, \" sd \",sd))\n",
    "      \n",
    "round(ci,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [ 2.90096224  2.09152418  0.10563911  0.07744745 -0.17163314 -0.13123873\n",
      "  0.13172712  0.02272241 -0.09728269 -0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:320: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  p = (norm.cdf(bb) - norm.cdf(zz)) / (norm.cdf(bb) - norm.cdf(aa))\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:328: RuntimeWarning: overflow encountered in exp\n",
      "  # https://math.uc.edu/~brycw/preprint/z-tail/z-tail.pdf\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:330: RuntimeWarning: overflow encountered in exp\n",
      "  if aa > -np.inf:\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:333: RuntimeWarning: overflow encountered in exp\n",
      "  if bb < np.inf:\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:334: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  term2 = ff(bb) * np.exp(-(bb**2 - zz**2) / 2)\n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:365: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \n",
      "/Users/bs224/Dropbox/PostDoc/projects/GELMMnet/GELMMnet/GELMMnet.py:366: RuntimeWarning: invalid value encountered in less_equal\n",
      "  jj = np.where(vals <= val2)[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pval</th>\n",
       "      <th>coef0</th>\n",
       "      <th>beta</th>\n",
       "      <th>Zscore</th>\n",
       "      <th>lower_confidence</th>\n",
       "      <th>upper_confidence</th>\n",
       "      <th>lower_trunc</th>\n",
       "      <th>upper_trunc</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.911576</td>\n",
       "      <td>2.900962</td>\n",
       "      <td>343.817563</td>\n",
       "      <td>0.846837</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.122611</td>\n",
       "      <td>2.091524</td>\n",
       "      <td>251.143377</td>\n",
       "      <td>0.845179</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141078</td>\n",
       "      <td>0.105639</td>\n",
       "      <td>14.856207</td>\n",
       "      <td>0.125280</td>\n",
       "      <td>0.156866</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.048205</td>\n",
       "      <td>0.009496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109437</td>\n",
       "      <td>0.077447</td>\n",
       "      <td>12.723478</td>\n",
       "      <td>0.095218</td>\n",
       "      <td>0.123652</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>0.049206</td>\n",
       "      <td>0.008601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.205650</td>\n",
       "      <td>-0.171633</td>\n",
       "      <td>-22.562943</td>\n",
       "      <td>-0.220679</td>\n",
       "      <td>-0.190548</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.048769</td>\n",
       "      <td>0.009115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.144647</td>\n",
       "      <td>-0.131239</td>\n",
       "      <td>-17.608818</td>\n",
       "      <td>-0.158321</td>\n",
       "      <td>-0.130999</td>\n",
       "      <td>0.047984</td>\n",
       "      <td>0.048310</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141072</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>16.537498</td>\n",
       "      <td>0.126986</td>\n",
       "      <td>0.155186</td>\n",
       "      <td>0.049343</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.008530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.045156</td>\n",
       "      <td>0.022722</td>\n",
       "      <td>5.530623</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.008165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.112833</td>\n",
       "      <td>-0.097283</td>\n",
       "      <td>-13.143687</td>\n",
       "      <td>-0.127091</td>\n",
       "      <td>-0.098712</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.049999</td>\n",
       "      <td>0.008585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pval     coef0      beta      Zscore  lower_confidence  \\\n",
       "variable                                                               \n",
       "0.0       0.000000  2.911576  2.900962  343.817563          0.846837   \n",
       "1.0       0.000000  2.122611  2.091524  251.143377          0.845179   \n",
       "2.0       0.000000  0.141078  0.105639   14.856207          0.125280   \n",
       "3.0       0.000000  0.109437  0.077447   12.723478          0.095218   \n",
       "4.0       0.000000 -0.205650 -0.171633  -22.562943         -0.220679   \n",
       "5.0       0.000000 -0.144647 -0.131239  -17.608818         -0.158321   \n",
       "6.0       0.000000  0.141072  0.131727   16.537498          0.126986   \n",
       "7.0       0.000005  0.045156  0.022722    5.530623          0.031073   \n",
       "8.0       0.000000 -0.112833 -0.097283  -13.143687         -0.127091   \n",
       "\n",
       "          upper_confidence  lower_trunc  upper_trunc        sd  \n",
       "variable                                                        \n",
       "0.0                    inf     0.000000     0.000000  0.008468  \n",
       "1.0                    inf     0.000000     0.000000  0.008452  \n",
       "2.0               0.156866     0.048089     0.048205  0.009496  \n",
       "3.0               0.123652     0.049147     0.049206  0.008601  \n",
       "4.0              -0.190548     0.049587     0.048769  0.009115  \n",
       "5.0              -0.130999     0.047984     0.048310  0.008214  \n",
       "6.0               0.155186     0.049343     0.049011  0.008530  \n",
       "7.0               0.058730     0.049478     0.048200  0.008165  \n",
       "8.0              -0.098712     0.048364     0.049999  0.008585  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GELMMnet import GELMMnet\n",
    "\n",
    "g = GELMMnet(y, x, np.identity(x.shape[0]))\n",
    "loss, w = g.train(np.identity(x.shape[1]), lmm=False, l1=0.8, l2=0, eps=1e-8)\n",
    "g.post_selection_analysis(lmm=False,alpha=0.1,compute_intervals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
